# CLAUDE.md - AI Assistant Guide for ARES

**Version**: 1.1
**Last Updated**: 2025-12-05
**Repository**: Advanced Relation Extraction System (ARES)

---

## Table of Contents

1. [AI Model Selection](#ai-model-selection) ‚ö†Ô∏è **READ FIRST**
2. [Project Overview](#project-overview)
3. [Quick Start](#quick-start)
4. [Architecture](#architecture)
5. [Development Workflows](#development-workflows)
6. [Testing Strategy](#testing-strategy)
7. [Code Organization](#code-organization)
8. [Key Conventions](#key-conventions)
9. [Common Tasks](#common-tasks)
10. [Debugging Guide](#debugging-guide)
11. [Documentation Index](#documentation-index)

---

## AI Model Selection

### ‚ö†Ô∏è MODEL SELF-CHECK - EVALUATE BEFORE EVERY TASK

**Before proceeding, determine if you are the right model for this task:**

| Task Type | Recommended Model | Warning |
|-----------|-------------------|---------|
| Simple edit, typo fix, search | **HAIKU** | If you are OPUS/SONNET doing this, you're wasting resources |
| Feature implementation (1-3 files) | **SONNET** | Default for development work |
| Architecture, multi-file refactor (>5 files) | **OPUS** | Only escalate when truly needed |
| Inline code completion | **CODEX** | Use IDE integration |

### Emit Warnings When Mismatched

**If you are OPUS/SONNET handling a simple task, emit:**
```
‚ö†Ô∏è MODEL EFFICIENCY: This task is simple enough for HAIKU.
Task: [describe task]
Recommendation: Use Claude Haiku or GPT-3.5 to conserve resources.
```

**If you are HAIKU/SONNET and task seems too complex, emit:**
```
‚ö†Ô∏è MODEL CAPABILITY: This task may need OPUS.
Reason: [>5 files / architecture decision / complex debugging]
Recommendation: Escalate to Claude Opus or GPT-4.
```

**If task involves linguistic understanding (entity extraction bugs, pronoun resolution):**
```
‚ö†Ô∏è LINGUISTIC EXPERTISE: The user is an English language expert.
STOP technical debugging. ASK THE USER for linguistic rules.
Question: "What's the linguistic rule for [specific ambiguity]?"
```

### Quick Decision Tree

```
Is this a simple edit/search? ‚Üí HAIKU
Is this feature implementation? ‚Üí SONNET (default)
Is this architecture or >5 files? ‚Üí OPUS
Am I stuck >30 minutes? ‚Üí ASK USER or escalate to OPUS
Is this a linguistic issue? ‚Üí ASK USER (they're the expert)
```

**Full guide:** See `docs/AI_MODEL_GUIDE.md` for detailed model selection criteria.

---

## Project Overview

### What is ARES?

ARES is a **local-first entity and relation extraction system** that builds knowledge graphs from unstructured text. It extracts entities (people, places, organizations, dates) and their relationships (parent_of, works_at, married_to) with full provenance tracking.

**Core Philosophy:**
- **Local-first**: No cloud dependencies, runs entirely offline
- **Deterministic**: Rule-based extraction with transparent, testable patterns
- **Provenance-first**: Every fact includes source text and evidence
- **Progressive quality**: 5-stage testing ladder from simple to production-ready

### Current Status (December 2025)

**Test Results:**
- ‚úÖ **Stage 1-3**: PASSED - All targets exceeded
- ‚úÖ **Level 5**: 96.3% (52/54 tests passing)
- ‚è∏Ô∏è **Stage 4-5**: Not started (scale testing)

**Extraction Quality:**
- Entity Precision: 90.2% (target ‚â•80%) ‚úÖ
- Entity Recall: 91.3% (target ‚â•75%) ‚úÖ
- Relation Precision: 80.8% (target ‚â•80%) ‚úÖ
- Relation Recall: 75.8% (target ‚â•75%) ‚úÖ
- Performance: ~190 words/second

**Recent Work:**
- Chunked extraction for long documents (55k+ words)
- Sibling detection pattern (FM-1) implemented
- Level 5 cross-document resolution working

### Key Features

- **Multi-pass extraction**: Dependency parsing + pattern matching + NER + coreference
- **HERT System**: Stable, compact entity references with precise locations
- **Alias resolution**: Maps name variations to single entities
- **Cross-document identity**: Maintains entity identity across multiple documents
- **GraphQL API**: Flexible query interface with caching and rate limiting
- **Extraction Lab**: Browser-based testing interface at `/lab`

---

## Quick Start

### Prerequisites

- **Node.js** 16+ and npm
- **Python** 3.8+ with pip
- **Make** (for running commands)

### Initial Setup (5 minutes)

```bash
# 1. Install dependencies
make install

# 2. Start spaCy parser service (Terminal 1)
make parser
# Wait for: "Application startup complete"

# 3. Run tests (Terminal 2)
make test        # Expected: 119/119 passing ‚úÖ
make smoke       # Quick validation

# 4. Start development server (optional)
make server-graphql  # GraphQL API on port 4000
```

### Verify Everything Works

```bash
# Check parser is running
curl -s http://127.0.0.1:8000/health
# Should return: {"status": "ok"}

# Run Stage 1 tests
npm test tests/ladder/level-1-simple.spec.ts
# Should pass with P‚â•90%, R‚â•85%
```

---

## Architecture

### System Pipeline

```
Raw Text
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  spaCy Parser   ‚îÇ (Python service, port 8000)
‚îÇ  NLP Analysis   ‚îÇ - Tokenization, POS tagging
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò - Dependency parsing, NER
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Entity Extract  ‚îÇ Multi-source extraction:
‚îÇ (3 stages)      ‚îÇ 1. Pattern-based aliases
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò 2. Coreference resolution
         ‚îÇ          3. Partial name variants
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Relation Extract‚îÇ - Dependency paths
‚îÇ Confidence      ‚îÇ - Pattern matching
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò - Inverse generation
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Knowledge Graph ‚îÇ - Entities + Relations + Evidence
‚îÇ GraphQL API     ‚îÇ - Query and visualization
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Core Components

**1. Engine (`app/engine/`)**
- **extract/entities.ts** (2898 lines) - Core entity extraction with 3-stage alias matching
- **extract/relations.ts** - Dependency path patterns for relation extraction
- **extract/orchestrator.ts** - Main coordinator, inverse relation generation
- **narrative-relations.ts** - Pattern-based narrative extraction
- **alias-resolver.ts** - Alias resolution and entity merging
- **coref.ts** - Coreference resolution

**2. Storage (`app/storage/`)**
- SQLite-based local storage
- HERT encoding for compact entity references
- Provenance tracking for all extractions

**3. API (`app/api/`)**
- GraphQL server with resolvers
- Caching layer for performance
- Rate limiting and pagination

**4. Parser (`app/parser/`)**
- Client for spaCy parser service
- Fallback to mock parser for testing

**5. UI (`app/ui/`)**
- **console/** - React-based extraction console
- **review-dashboard/** - Entity/relation review interface
- **Extraction Lab** - Browser-based testing at `/lab`

### HERT System (Hierarchical Entity Reference Tag)

**Format:** `HERTv1:1J8trXOyn4HRaWXrdh9TUE`

**Decodes to:**
- EID 43 (stable entity ID)
- AID 230 (surface form)
- Document fingerprint
- Paragraph 0, tokens 0-14

**Benefits:**
- **Stable**: EID doesn't change when entity name changes
- **Compact**: 20-30 chars vs 200+ for JSON
- **Precise**: Exact paragraph + token location
- **Portable**: Share via URL, no database needed

**Location:** `app/engine/hert/`

---

## Development Workflows

### Before Making ANY Changes

```bash
# 1. Read the essential docs
cat README.md                           # Project overview
cat INTEGRATED_TESTING_STRATEGY.md     # Testing approach
cat docs/ARES_PROJECT_BRIEFING.md      # Latest status

# 2. Verify baseline tests pass
make parser  # Terminal 1 (keep running)
npm test tests/ladder/level-1-simple.spec.ts  # Terminal 2

# 3. Check current status
cat INTEGRATED_TESTING_STRATEGY.md | grep "Status:"
```

### Standard Development Loop

```bash
# 1. Create feature branch
git checkout -b feature/your-feature-name

# 2. Make incremental changes
# Edit files...

# 3. Test AFTER EACH change (don't batch!)
npm test tests/ladder/level-1-simple.spec.ts

# 4. Run relevant stage tests
npm test tests/ladder/level-2-multisentence.spec.ts  # If Stage 2 work

# 5. ‚ö†Ô∏è STUCK ON A BUG? Ask the user for help!
# If the bug involves natural language (entity extraction, pronoun resolution,
# relation patterns, etc.), ASK THE USER immediately instead of debugging >30min.
# The user is an English language expert who can provide linguistic rules.

# 6. Commit with descriptive message
git add -A
git commit -m "feat: add support for X"

# 7. Push to designated branch
git push -u origin claude/claude-md-miex9940wrme9tpt-01Jd9AfTTZNzdiNeQ7jgvkmh
```

### Git Workflow Requirements

**CRITICAL Git Rules:**
- Always use: `git push -u origin <branch-name>`
- Branch MUST start with `claude/` and end with matching session ID
- If push fails with network error, retry up to 4 times with exponential backoff (2s, 4s, 8s, 16s)
- NEVER use `--force` on main/master
- NEVER skip hooks with `--no-verify` unless explicitly requested
- NEVER update git config
- Check authorship before amending: `git log -1 --format='%an %ae'`

### Commit Message Format

```bash
# Use HEREDOC for proper formatting
git commit -m "$(cat <<'EOF'
feat: Add partial name variant matching for entity aliases

- Implement name decomposition for compound names
- Add proximity gating (~500 chars) to prevent false positives
- Merge abbreviated first names (Mike ‚Üí Michael)
- Target: improve complex-person-002 test case

Iteration 37
EOF
)"
```

---

## Testing Strategy

### The Five-Stage Testing Ladder

ARES uses a **single progressive ladder** where each stage validates both component health AND extraction quality.

**Key Principle**: Check component health FIRST, then test extraction quality.

#### Stage 1: Foundation ‚úÖ PASSED
```bash
# 1.1 Pattern Coverage Audit (‚â•30%)
npx ts-node scripts/pattern-expansion/inventory-patterns.ts

# 1.2 Entity Quality Check
# Verify entity types are valid

# 1.3 Simple Sentence Extraction (P‚â•90%, R‚â•85%)
npm test tests/ladder/level-1-simple.spec.ts
```

**Status**: ‚úÖ PASSED
**Test Cases**: 20 simple sentences

#### Stage 2: Component Validation ‚ö†Ô∏è 99%
```bash
# 2.1 Synthetic Baseline (F1‚â•10%)
npx tsx scripts/pattern-expansion/evaluate-coverage.ts

# 2.2 Precision Guardrails Test
npx tsx scripts/pattern-expansion/evaluate-coverage.ts --precision_guardrails

# 2.3 Multi-Sentence Extraction (P‚â•85%, R‚â•80%)
npm test tests/ladder/level-2-multisentence.spec.ts
```

**Status**: ‚ö†Ô∏è 99% COMPLETE
**Blocker**: Test 2.12 - appositive parsing issue
**Test Cases**: 15 multi-sentence narratives

#### Stage 3: Complex Extraction ‚è∏Ô∏è NOT STARTED
```bash
# 3.1 Cross-Sentence Coreference
# To be created

# 3.2 Pattern Family Coverage (‚â•50%)
npx ts-node scripts/pattern-expansion/audit-integration.ts

# 3.3 Complex Paragraph Extraction (P‚â•80%, R‚â•75%)
npm test tests/ladder/level-3-complex.spec.ts
```

**Status**: ‚è∏Ô∏è NOT STARTED (blocked on Stage 2)

#### Stage 4: Scale Testing ‚è∏Ô∏è FUTURE
```bash
# 4.1 Performance Benchmarks (‚â•100 words/sec)
# 4.2 Memory Profile
# 4.3 Mega Regression Test
npm run test:mega
```

#### Stage 5: Production Readiness ‚è∏Ô∏è FUTURE
```bash
# 5.1 Canary Corpus Evaluation
npx tsx scripts/pattern-expansion/evaluate-coverage.ts --canary corpora/canary_realtext.jsonl
# 5.2 Real-World Validation
# 5.3 Edge Case Coverage
```

### Testing Commands Reference

```bash
# Run all tests
make test

# Run specific stage
npm test tests/ladder/level-1-simple.spec.ts  # Stage 1
npm test tests/ladder/level-2-multisentence.spec.ts  # Stage 2
npm test tests/ladder/level-3-complex.spec.ts  # Stage 3
npm run test:mega  # Stage 4

# Debug tests with verbose output
L3_DEBUG=1 npm test tests/ladder/level-2-multisentence.spec.ts

# Run debug runners
npx ts-node tests/ladder/run-level-1.ts
npx ts-node tests/ladder/run-level-2.ts

# Component health checks
npx ts-node scripts/pattern-expansion/inventory-patterns.ts
npx tsx scripts/pattern-expansion/evaluate-coverage.ts
```

### Test Failure Diagnosis

**Stage 1 failures** ‚Üí Foundational issues
- Missing basic patterns
- Entity types wrong
- Parser not running

**Stage 2 failures** ‚Üí Integration issues
- Low synthetic baseline (need more patterns)
- Guardrails too aggressive
- Coreference broken

**Stage 3+ failures** ‚Üí Complexity issues
- Insufficient pattern coverage
- Long-distance dependencies not handled
- Performance degradation

---

## Code Organization

### Directory Structure

```
ARES/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ engine/              # Core extraction engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extract/         # Entity & relation extraction
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entities.ts  # 3-stage entity extraction (2898 lines)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ relations.ts # Dependency path patterns
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.ts  # Main coordinator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hert/            # HERT encoding/decoding
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grammar/         # POS tagging, sentence analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm-providers/   # LLM integration (optional)
‚îÇ   ‚îú‚îÄ‚îÄ storage/             # SQLite data persistence
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # GraphQL API & resolvers
‚îÇ   ‚îú‚îÄ‚îÄ parser/              # spaCy parser client
‚îÇ   ‚îú‚îÄ‚îÄ editor/              # Entity highlighter
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ entityHighlighter.ts  # Regex patterns (1000+ lines)
‚îÇ   ‚îî‚îÄ‚îÄ ui/                  # Web interfaces
‚îÇ       ‚îú‚îÄ‚îÄ console/         # React extraction console
‚îÇ       ‚îî‚îÄ‚îÄ review-dashboard/  # Entity review UI
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ ladder/              # Progressive stage tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ level-1-simple.spec.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ level-2-multisentence.spec.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ level-3-complex.spec.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run-level-*.ts   # Debug runners
‚îÇ   ‚îú‚îÄ‚îÄ golden/              # Golden corpus tests
‚îÇ   ‚îú‚îÄ‚îÄ integration/         # API tests
‚îÇ   ‚îî‚îÄ‚îÄ entity-extraction/   # Entity extraction regression (28 tests)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ pattern-expansion/   # Pattern coverage tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inventory-patterns.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate-coverage.ts
‚îÇ   ‚îú‚îÄ‚îÄ parser_service.py    # spaCy parser service
‚îÇ   ‚îî‚îÄ‚îÄ diagnose-l2.ts       # Diagnostic tools
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ architecture/        # Technical designs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ HERT_IMPLEMENTATION.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ENGINE_EVOLUTION_STRATEGY.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MANUAL_OVERRIDE_DESIGN.md
‚îÇ   ‚îú‚îÄ‚îÄ guides/              # User guides
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ QUICK_START.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DESKTOP_TESTER_QUICKSTART.md
‚îÇ   ‚îú‚îÄ‚îÄ reference/           # API reference
‚îÇ   ‚îî‚îÄ‚îÄ ARES_PROJECT_BRIEFING.md  # Latest status
‚îú‚îÄ‚îÄ data/                    # Local SQLite storage
‚îú‚îÄ‚îÄ patterns/                # Relation pattern definitions
‚îî‚îÄ‚îÄ reports/                 # Test reports

Key Files:
- README.md                  # Project overview
- HANDOFF.md                 # Latest session status
- INTEGRATED_TESTING_STRATEGY.md  # Testing approach
- ENTITY_EXTRACTION_STATUS.md  # Entity system docs
- CHANGELOG.md               # Version history
- Makefile                   # Build commands
- package.json               # Node dependencies
- tsconfig.json              # TypeScript config
```

### File Count by Module

- **Engine**: 72 TypeScript files
- **Tests**: 40+ test files
- **API**: 20+ resolver files
- **Documentation**: 30+ markdown files

---

## Key Conventions

### 1. Entity IDs (HERT System)

```typescript
// ‚úÖ Use stable HERT IDs
const relation = {
  subjectId: 'EID_Gandalf_wiz_a7b3c9',
  predicate: 'mentor_of',
  objectId: 'EID_Frodo_hob_d4e2f8'
};

// ‚ùå Don't use entity names directly
const relation = {
  subject: 'Gandalf',  // Breaks if name changes
  object: 'Frodo'
};
```

### 2. Evidence Provenance

```typescript
// ‚úÖ Always include source text span
const relation = {
  subjectId: 'EID_Aragorn',
  predicate: 'married_to',
  objectId: 'EID_Arwen',
  evidence: {
    text: 'Aragorn married Arwen',
    sourceDoc: 'chapter-20.md',
    paragraphIndex: 5,
    tokenStart: 12,
    tokenEnd: 18
  }
};
```

### 3. Confidence Scoring

```typescript
// New entities created with confidence: 0.99
const entity = {
  id: generateEID(name, type),
  name: 'Gandalf',
  type: 'PERSON',
  confidence: 0.99,  // High confidence for explicit mentions
  aliases: ['Gandalf the Grey', 'Mithrandir']
};
```

### 4. Type Normalization

```typescript
// Test layer normalization:
ORGANIZATION ‚Üí ORG
LOCATION ‚Üí PLACE
PRODUCT/SOFTWARE_LIBRARY ‚Üí ITEM
LAW ‚Üí WORK

// Applied in: tests/entity-extraction/extraction.spec.ts
```

### 5. Deterministic Behavior

```typescript
// ‚úÖ Alphabetical sorting for consistency
entities.sort((a, b) => a.name.localeCompare(b.name));

// ‚úÖ Consistent field ordering
const relation = {
  id, subjectId, predicate, objectId, evidence, confidence
};

// ‚ùå Don't add randomness
Math.random()  // NEVER use this!
```

### 6. Local-First Design

```typescript
// ‚úÖ Use local SQLite
const db = await SQLite.open({
  filename: './data/ares.db'
});

// ‚ùå Don't require cloud for core functionality
const data = await fetch('https://api.ares.com/entities');  // BAD!
```

### 7. Inverse Relations

```typescript
// Auto-generate inverse relations
const INVERSE = {
  parent_of: 'child_of',
  child_of: 'parent_of',
  married_to: 'married_to',  // Symmetric
  founded: 'founded_by',
  founded_by: 'founded',
};

// In orchestrator.ts:301-318
if (INVERSE[relation.pred]) {
  const inverse = {
    ...relation,
    id: uuid(),
    subj: relation.obj,
    obj: relation.subj,
    pred: INVERSE[relation.pred]
  };
  inverseRelations.push(inverse);
}
```

### 8. Pronoun Filtering

```typescript
// ‚úÖ Filter context-dependent pronouns from aliases
const PRONOUNS = ['he', 'she', 'they', 'his', 'her', 'their'];
aliases = aliases.filter(a => !PRONOUNS.includes(a.toLowerCase()));

// Context: Iteration 37 - filter pronouns from coreference-resolved aliases
// Location: app/engine/extract/entities.ts:2855-2891
```

---

## UI Development Pitfalls

### Safari/iOS Backdrop-Filter Issue

**CRITICAL:** `backdrop-filter` (blur effects) breaks when used inside elements with CSS transforms.

**The Problem:**
When a parent element has `transform` property (e.g., `translateX(-50%)`), it creates a new containing block. Children with `position: fixed` are then positioned relative to that parent, NOT the viewport. This breaks the rendering context for `backdrop-filter` on Safari/iOS.

**Example of Broken Code:**
```jsx
<div style={{ transform: 'translateX(-50%)' }}>  {/* ‚Üê Creates containing block */}
  <div style={{ position: 'fixed', backdropFilter: 'blur(12px)' }}>
    {/* ‚ùå Blur won't work on Safari! */}
  </div>
</div>
```

**Solution: Use React Portal**
```jsx
import { createPortal } from 'react-dom';

function MyComponent() {
  return (
    <>
      <div className="parent-with-transform">
        <button>Click me</button>
      </div>

      {/* Portal renders at document.body, escaping transform context */}
      {showDropdown && createPortal(
        <div style={{ position: 'fixed', backdropFilter: 'blur(12px)' }}>
          {/* ‚úÖ Blur works! */}
        </div>,
        document.body
      )}
    </>
  );
}
```

**Key Requirements for backdrop-filter on Safari:**
1. Element must be in clean stacking context (no parent transforms)
2. Add `isolation: isolate` to create isolated stacking context
3. Add `transform: translateZ(0)` for GPU acceleration
4. Background must be semi-transparent (alpha < 1.0)
5. Avoid complex animations with transforms
6. Use `!important` if needed to override conflicting styles

**Reference:** See `app/ui/console/src/components/LabToolbar.tsx` for working implementation.

---

## Common Tasks

### Task 1: Add a New Relation Pattern

**Example:** Add support for "X founded Y" relations

```bash
# 1. Add predicate to schema (if new)
# File: app/engine/schema.ts or app/engine/extract/relations/types.ts

# In PREDICATE_WEIGHTS:
founded: 0.80,

# In INVERSE map:
founded: 'founded_by',
founded_by: 'founded',

# 2. Add dependency pattern
# File: app/engine/extract/relations.ts

{
  subj: 'nsubj',    # Subject dependency
  obj: 'dobj',      # Object dependency
  pred: 'founded',
  tokens: ['founded', 'established', 'created']
},

# 3. Add narrative pattern (optional)
# File: app/engine/narrative-relations.ts

if (sentence.includes('founded') || sentence.includes('established')) {
  // Extract entities and create relation
}

# 4. Add test case
# File: tests/ladder/level-1-simple.spec.ts

{
  text: 'Steve Jobs founded Apple in 1976.',
  gold: {
    entities: ['Steve Jobs:PERSON', 'Apple:ORG'],
    relations: ['Steve Jobs --[founded]--> Apple']
  }
}

# 5. Run tests
npm test tests/ladder/level-1-simple.spec.ts
```

### Task 2: Debug Extraction Failure

**Example:** Relations not being extracted for certain patterns

```bash
# 1. Check parser is running
curl -s http://127.0.0.1:8000/health

# 2. Create debug script
cat > debug-extraction.ts <<'EOF'
import { extractFromText } from './app/engine/extract/orchestrator'

const text = 'Your test sentence here.'
const result = await extractFromText(text)

console.log('Entities:', result.entities)
console.log('Relations:', result.relations)
EOF

# 3. Run with debug output
L3_DEBUG=1 npx ts-node debug-extraction.ts

# 4. Check spaCy output directly
curl -X POST http://127.0.0.1:8000/parse \
  -H "Content-Type: application/json" \
  -d '{"text": "Your sentence"}'

# 5. Use diagnostic tool
npx ts-node scripts/diagnose-l2.ts
```

### Task 3: Improve Pattern Coverage

**Current:** 26% (480/1827 patterns)
**Target:** ‚â•30% for Stage 1, ‚â•50% for Stage 3

```bash
# 1. Check current coverage
npx ts-node scripts/pattern-expansion/inventory-patterns.ts
# Output: reports/rung1_pattern_coverage_summary.md

# 2. Identify gaps
cat reports/rung1_pattern_coverage_summary.md

# 3. Add patterns to relevant files
# - app/engine/extract/relations.ts (dependency patterns)
# - app/engine/narrative-relations.ts (narrative patterns)
# - patterns/*.json (pattern libraries)

# 4. Validate improvement
npx tsx scripts/pattern-expansion/evaluate-coverage.ts

# 5. Run stage tests
npm test tests/ladder/level-1-simple.spec.ts
```

### Task 4: Fix Entity Type Coverage

**Example:** Missing ORGANIZATION entities in extraction

```bash
# 1. Check entity extraction test results
npx vitest tests/entity-extraction/extraction.spec.ts

# 2. Identify failing test cases
# Look for: "Missing ORGANIZATION entities: Apple, TechCrunch, FBI"

# 3. Update entity classification
# File: app/engine/extract/entities.ts

function classifyEntity(span: string, label: string): EntityType {
  // Add ORG detection logic
  if (isOrganization(span, label)) return 'ORG'
  // ...
}

# 4. Add NER patterns (if needed)
# File: app/parser/index.ts or MockParserClient

# 5. Test specific case
npx vitest tests/entity-extraction/extraction.spec.ts -t "organization-001"
```

### Task 5: Update Documentation

```bash
# 1. Check existing docs first (avoid duplication!)
grep -r "your topic" docs/

# 2. Update relevant file
# - README.md - Project overview
# - HANDOFF.md - Session status
# - docs/ARES_PROJECT_BRIEFING.md - Latest briefing
# - INTEGRATED_TESTING_STRATEGY.md - Testing approach
# - CHANGELOG.md - Version history

# 3. Follow markdown style
# - Use ## for sections, ### for subsections
# - Include code blocks with language tags
# - Add line numbers for file references
# - Keep concise and action-oriented

# 4. Commit documentation changes separately
git add docs/
git commit -m "docs: Update architecture guide with HERT examples"
```

---

## Debugging Guide

### ‚ö†Ô∏è CRITICAL: When to Ask for User Help

**The user is an English language expert. When you encounter bugs involving natural language understanding, ASK FOR HELP IMMEDIATELY instead of spinning your wheels on technical debugging.**

**ALWAYS ask the user for help when:**

1. **Entity/Relation Extraction Bugs** - Entities merging incorrectly, pronouns resolving wrong, coreference issues
   - Example: "Harry Potter and Lily Potter are merging into one entity"
   - ‚úÖ Ask: "These entities with shared surnames are merging. What's the linguistic rule for handling this?"
   - ‚ùå Don't: Spend hours debugging merge.ts without understanding the linguistic requirement

2. **Pattern Matching Issues** - Relations not extracting for certain sentence structures
   - Example: "The system isn't catching 'His father Arthur worked...'"
   - ‚úÖ Ask: "In 'Ron came from a family. His father Arthur worked...', should 'His' refer to Ron? What's the rule?"
   - ‚ùå Don't: Try random pattern variations without understanding the grammar

3. **Ambiguous Linguistic Situations** - Any case where multiple interpretations are possible
   - Example: "Should 'Potter' alone resolve to Harry or Lily?"
   - ‚úÖ Ask: "When a surname appears alone after both 'Harry Potter' and 'Lily Potter', which should it resolve to?"
   - ‚ùå Don't: Implement arbitrary rules without linguistic guidance

4. **Stuck After 30+ Minutes** - If you've spent >30 minutes on any bug without progress
   - ‚úÖ Ask: Provide the specific example, explain what you've tried, ask for linguistic guidance
   - ‚ùå Don't: Continue technical debugging without checking if it's a linguistic rules problem

**How to Ask for Help:**
```markdown
I'm stuck on [specific bug]. Here's the example:

Text: "[exact sentence from test]"
Expected: [what should happen]
Actual: [what's happening]

I've tried: [technical approaches]

Question: What's the linguistic rule for [the ambiguous situation]?
```

**Real Example from Harry/Lily Potter Bug:**
- ‚ùå Wrong approach: Spent hours modifying merge.ts to block surname-only matches
- ‚úÖ Right approach: "These entities share 'Potter' surname and are merging. What's the linguistic rule?"
- User's answer: "Use recency - if last Potter mentioned was Harry, 'Potter' refers to Harry"
- Result: Bug fixed in 1 hour instead of spinning for days

**Remember:** The user's linguistic expertise can solve in minutes what technical debugging can't solve in hours.

---

### üîç First Step: Check the Linguistic Reference

**Before asking the user or debugging code, consult the ARES Linguistic Reference:**

```bash
# Open the linguistic reference
cat docs/LINGUISTIC_REFERENCE.md
```

**This document contains:**
- **30+ linguistic patterns** for pronoun resolution, coreference, apposition, bridging, etc.
- **Bug patterns (¬ß30)** - Common mistakes and their fixes
- **Test templates (¬ß32)** - Patterns mapped to test cases
- **Resolution pipeline (¬ß1)** - Step-by-step reference resolution algorithm

**When to use it:**
1. **Test failures** - Look up the failing pattern (e.g., test 2.12 ‚Üí appositive parsing ‚Üí see ¬ß9 Pattern AP-3)
2. **Entity merging issues** - Check ¬ß30.3 (Surname Merging) or ¬ß6 (Names and Surnames)
3. **Pronoun resolution bugs** - See ¬ß2 (Personal Pronouns) and ¬ß11 (Salience)
4. **Dialogue attribution** - Check ¬ß16 (Dialogue and Quotation Handling)
5. **Group vs individual confusion** - See ¬ß7 (Groups, Families, Collectives) and ¬ß30.4

**Example workflow:**
```bash
# Test 2.12 fails (appositive: "Aragorn, son of Arathorn")
# 1. Search linguistic reference
grep -A 10 "appositive\|AP-" docs/LINGUISTIC_REFERENCE.md

# 2. Find Pattern AP-3: "Name + Role Apposition"
# "Severus Snape, the Potions Master" ‚Üí same PERSON + role relation

# 3. Apply pattern to "Aragorn, son of Arathorn"
# ‚Üí "son of" indicates child_of relation
# ‚Üí Extract: Aragorn child_of Arathorn

# 4. If pattern exists but code doesn't implement it ‚Üí fix code
# 5. If pattern is missing ‚Üí add to linguistic reference first, then code
```

**The debugging pipeline:**
1. ‚úÖ **Check linguistic reference** for known patterns (¬ß1-¬ß32)
2. ‚úÖ **Check bug patterns** (¬ß30) for common mistakes
3. ‚úÖ Try implementing the documented pattern
4. ‚ùå If stuck after 30min ‚Üí **Ask user for linguistic guidance**
5. ‚úÖ Once resolved ‚Üí **Update linguistic reference** if pattern was missing

---

### Parser Issues

```bash
# Check if parser is running
curl -s http://127.0.0.1:8000/health
# Expected: {"status": "ok"}

# Start parser if not running
make parser

# Check parser logs
# Terminal 1: make parser
# Look for startup messages

# Test parser directly
curl -X POST http://127.0.0.1:8000/parse \
  -H "Content-Type: application/json" \
  -d '{"text": "Aragorn married Arwen."}'

# Check for connection errors in tests
# Error: "ECONNREFUSED 127.0.0.1:8000" ‚Üí Parser not running
```

### Test Failures

```bash
# Stage 1 failing?
npm test tests/ladder/level-1-simple.spec.ts
# Check: Pattern coverage, entity types, parser running

# Stage 2 failing?
npm test tests/ladder/level-2-multisentence.spec.ts
# Check: Coreference resolution, pronoun handling, multi-sentence patterns

# Run debug runner for detailed output
npx ts-node tests/ladder/run-level-2.ts
# Look for: Missing relations, suppressed extractions, entity mismatches

# Enable verbose logging
L3_DEBUG=1 npm test tests/ladder/level-2-multisentence.spec.ts

# Check specific test
npm test tests/ladder/level-2-multisentence.spec.ts -t "2.12"
```

### Entity Extraction Issues

```bash
# Run entity extraction regression suite
npx vitest tests/entity-extraction/extraction.spec.ts

# Check specific test case
npx vitest tests/entity-extraction/extraction.spec.ts -t "basic-person-001"

# Debug entity extraction with verbose output
L3_DEBUG=1 npx vitest tests/entity-extraction/extraction.spec.ts

# Check span traces
cat tmp/span-trace.log | head -50

# Diagnose entity issues
npx ts-node scripts/diagnose-entities.ts
```

### Performance Issues

```bash
# Run performance benchmark
npx ts-node tests/integration/performance.spec.ts

# Check mega test performance
npm run test:mega
# Target: ‚â•100 words/sec, ~190 words/sec current

# Profile memory usage
node --inspect-brk $(which npx) ts-node your-script.ts
# Open chrome://inspect in browser

# Check for bottlenecks
L3_DEBUG=1 npx ts-node your-script.ts
# Look for slow operations in logs
```

### Build Errors

```bash
# TypeScript errors
npx tsc --noEmit
# Check: Type mismatches, missing imports

# Dependency issues
rm -rf node_modules package-lock.json
npm install

# Python dependencies
rm -rf .venv
python3 -m venv .venv
. .venv/bin/activate
pip install -r scripts/requirements.txt
```

### Git Issues

```bash
# Push fails with 403?
# Check: Branch name must start with 'claude/' and end with session ID

# Push fails with network error?
# Retry with exponential backoff: 2s, 4s, 8s, 16s

# Conflict on pull?
git fetch origin claude/claude-md-miex9940wrme9tpt-01Jd9AfTTZNzdiNeQ7jgvkmh
git rebase origin/claude/claude-md-miex9940wrme9tpt-01Jd9AfTTZNzdiNeQ7jgvkmh

# Check commit authorship before amending
git log -1 --format='%an %ae'
```

---

## Documentation Index

### Essential Reading (Start Here)

1. **README.md** - Project overview, features, quick start
2. **INTEGRATED_TESTING_STRATEGY.md** - 5-stage testing ladder, current status
3. **docs/ARES_PROJECT_BRIEFING.md** - Iteration 37 status, recent work
4. **HANDOFF.md** - Latest session summary, next steps

### Development Guides

- **docs/LINGUISTIC_REFERENCE.md** - ‚≠ê **Linguistic patterns reference for debugging** (v0.4, 32 sections)
- **docs/FOR_AGENTS.md** - Quick onboarding for AI agents (10 min read)
- **CONTRIBUTING.md** - Architecture patterns, common pitfalls
- **docs/guides/QUICK_START.md** - Installation and setup
- **docs/guides/DESKTOP_TESTER_QUICKSTART.md** - Testing guide

### Architecture Documentation

- **docs/architecture/HERT_IMPLEMENTATION.md** - HERT system technical details
- **docs/architecture/HERT_INTEGRATION_GUIDE.md** - HERT integration guide
- **docs/architecture/ENGINE_EVOLUTION_STRATEGY.md** - Architecture strategy
- **docs/architecture/MANUAL_OVERRIDE_DESIGN.md** - Manual override system

### API & Reference

- **docs/reference/WIKI_QUICKSTART.md** - Wiki API quickstart
- **ENTITY_EXTRACTION_STATUS.md** - Entity detection system (744 lines)
- **CHANGELOG.md** - Version history and changes

### Testing Documentation

- **docs/testing/TESTING_STRATEGY.md** - Testing philosophy
- **docs/testing/reports/** - Test reports (pattern coverage, guardrails, etc.)

### Specialized Agents

- **.claude/agents/ares-dev.md** - Development agent instructions
- **.claude/agents/ares-guide.md** - Guide agent for architecture questions

### Historical Context

- **docs/archive/** - Historical reports and decisions
- **LESSONS_LEARNED.md** - Key insights from past work
- **SESSION_NOTES_*.md** - Session notes and findings

---

## Quick Reference Commands

### Setup & Build

```bash
make help            # Show all commands
make install         # One-time setup
make parser          # Start spaCy parser (port 8000)
make server-graphql  # Start GraphQL server (port 4000)
make clean           # Remove generated files
```

### Testing

```bash
make test            # Run all tests
make smoke           # Quick validation
npm test tests/ladder/level-1-simple.spec.ts  # Stage 1
npm test tests/ladder/level-2-multisentence.spec.ts  # Stage 2
npm run test:mega    # Large documents
L3_DEBUG=1 npm test  # Verbose output
```

### Development

```bash
npm run dev          # Start dev server
make ui-console      # Start console UI
make ui-console-dev  # Start console dev server
make ui-review       # Start review dashboard
```

### Debugging

```bash
npx ts-node tests/ladder/run-level-2.ts  # Debug runner
npx ts-node scripts/diagnose-l2.ts       # Diagnose Level 2
npx ts-node scripts/diagnose-entities.ts # Diagnose entities
```

### Pattern Coverage

```bash
npx ts-node scripts/pattern-expansion/inventory-patterns.ts  # Coverage audit
npx tsx scripts/pattern-expansion/evaluate-coverage.ts       # Metrics
npx tsx scripts/pattern-expansion/evaluate-coverage.ts --precision_guardrails  # With guardrails
```

### Git Workflow

```bash
git checkout -b feature/your-feature
# Make changes...
git add -A
git commit -m "feat: your message"
git push -u origin claude/claude-md-miex9940wrme9tpt-01Jd9AfTTZNzdiNeQ7jgvkmh
```

---

## Critical Reminders

### Always Do

- ‚úÖ **ASK USER FOR HELP when stuck on linguistic bugs (entity extraction, pronouns, patterns)**
- ‚úÖ Read README.md, INTEGRATED_TESTING_STRATEGY.md, and docs/ARES_PROJECT_BRIEFING.md first
- ‚úÖ Start parser before running tests: `make parser`
- ‚úÖ Verify Stage 1 passes before and after changes
- ‚úÖ Test incrementally after each change (don't batch!)
- ‚úÖ Check existing docs before creating new ones
- ‚úÖ Include evidence provenance for all extractions
- ‚úÖ Use HERT IDs for entity references
- ‚úÖ Maintain deterministic behavior (no randomness!)
- ‚úÖ Commit message format: `feat:`, `fix:`, `docs:`, `test:`
- ‚úÖ Push to correct branch with proper naming

### Never Do

- ‚ùå **Spend >30 minutes debugging linguistic issues without asking user (they're an English expert!)**
- ‚ùå Skip reading essential documentation
- ‚ùå Run tests without parser running
- ‚ùå Break lower stages when fixing higher stages
- ‚ùå Create redundant documentation
- ‚ùå Use entity names instead of HERT IDs
- ‚ùå Add randomness or non-deterministic behavior
- ‚ùå Push to main/master without permission
- ‚ùå Use `--force` on shared branches
- ‚ùå Skip hooks with `--no-verify`
- ‚ùå Modify git config

---

## Success Checklist

Before considering your work complete:

- [ ] Read essential documentation (README, INTEGRATED_TESTING_STRATEGY, BRIEFING)
- [ ] Parser is running (`make parser`)
- [ ] Stage 1 tests pass (baseline verification)
- [ ] All previously passing tests still pass
- [ ] New functionality has tests
- [ ] No redundant systems or documentation created
- [ ] Follows architecture patterns (HERT, evidence, local-first)
- [ ] Code is deterministic (no randomness)
- [ ] Documentation updated (if needed)
- [ ] Commit message is descriptive with proper prefix
- [ ] Changes committed to correct branch
- [ ] Ready to push with proper branch naming

---

## Contact & Resources

- **Repository**: https://github.com/mrfishcar/ARES
- **Issues**: https://github.com/mrfishcar/ARES/issues
- **Branch**: `claude/claude-md-miex9940wrme9tpt-01Jd9AfTTZNzdiNeQ7jgvkmh`
- **Documentation**: https://github.com/mrfishcar/ARES/tree/main/docs

---

**Last Updated**: 2025-11-25 (Iteration 37)
**Maintainers**: ARES Team
**License**: MIT

*This guide is maintained for AI assistants working on the ARES project. Keep it updated with significant architectural changes, new conventions, or workflow modifications.*
